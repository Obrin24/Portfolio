library(keras)
library(keras)
library(dplyr)
library(caret)
library(dplyr)
library(caret)
library(rpart)
library(rpart)
library(rpart.plot)
rm(list=ls())
# Set working directory as needed
setwd("C:/Users/gabeb/Desktop/programming/CS 422 Homework/Gabriel,Johnson")
df <- read.csv("wifi_localization.csv")
# Seed the PRNG
set.seed(1122)
df <- df[sample(nrow(df)), ] # Shuffle, as all of the data in the .csv file
View(df)
indx <- sample(1:nrow(df), 0.20*nrow(df))
indx <- sample(1:nrow(df), 0.20*nrow(df))
test.df  <- df[indx, ]
train.df <- df[-indx, ]
X_train <- select(train.df, -label)
library(keras)
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
X_train <- select(train.df, -label)
indx <- sample(1:nrow(df), 0.20*nrow(df))
test.df  <- df[indx, ]
train.df <- df[-indx, ]
X_train <- select(train.df, -label)
X_train <- select(train.df, -room)
y_train <- train.df$room
y_train.ohe <- to_categorical(y_train)
y_train.ohe <- to_categorical(y_train)
X_test <- select(test.df, -label)
X_test <- select(test.df, -room)
y_test <- test.df$room
y_test.ohe <- to_categorical(test.df$room)
View(y_train.ohe)
library(keras)
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
rm(list=ls())
options(digits=2)
# Set working directory as needed
setwd("C:/Users/gabeb/Desktop/programming/CS 422 Homework/Gabriel,Johnson")
library(keras)
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
rm(list=ls())
options(digits=2)
# Set working directory as needed
setwd("C:\Users\gabeb\Documents\GitHub\Portfolio\R Projects\Homework 5\Gabriel, Johnson")
library(keras)
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
rm(list=ls())
options(digits=2)
# Set working directory as needed
setwd("C:\Users\gabeb\Desktop\programming\CS 422 Homework\Old Homework\Homework 7")
library(keras)
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
rm(list=ls())
options(digits=2)
# Set working directory as needed
setwd("C:/Users/gabeb/Desktop/programming/CS 422 Homework/Old Homework/Homework 7")
df <- read.csv("wifi_localization.csv")
# Seed the PRNG
set.seed(1122)
df <- df[sample(nrow(df)), ] # Shuffle, as all of the data in the .csv file
# is ordered by label!
indx <- sample(1:nrow(df), 0.20*nrow(df))
test.df  <- df[indx, ]
train.df <- df[-indx, ]
model <- rpart(room ~.,method="class", data = train.df)
#rpart.plot(model, fallen.leaves=T, type=2, main="Wifi Room Decision Model")
predicted <- predict(model,test.df,type="class")
confMatrix <- confusionMatrix(predicted,as.factor(test.df[,8]))
confMatrix
x <- confMatrix[["byClass"]]
sensitivity <- x[1:4]
specificity <- x[5:8]
ppv <- x[9:12]
Bal_acc <- x[41:44]
accuracy <- confMatrix$overall['Accuracy']
cat("      Decision Tree Model \n\t Overall accuracy:", accuracy, "\n\t Sensitivity Class 1: ", sensitivity[1], "  Class 2:", sensitivity[2], "\n\t             Class 3:", sensitivity[3], "Class 4:", sensitivity[4], "\n\t Specificity Class 1:", specificity[1], "Class 2:", specificity[2], "\n\t\             Class 3:", specificity[3], "Class 4:", specificity[4],"\n\t PPV \t     Class 1:", ppv[1], "Class 2:", ppv[2], "\n\t             Class3: ", ppv[3], "Class 4:", ppv[4], "\n\t Bal. Acc.   Class 1:", Bal_acc[1], "Class 2:", Bal_acc[2], "\n\t             Class 3:", Bal_acc[3], "Class 4:", Bal_acc[4])
df2 <- df
df2$label <- rep(0, nrow(df2))
df2$label[df2$room == "2"] <- 1
df2$label[df2$room == "3"] <- 2
df2$label[df2$room == "4"] <- 3
df2$room <- NULL
set.seed(1122)
test2.df  <- df2[indx, ]
train2.df <- df2[-indx, ]
X_train <- select(train2.df, -label)
y_train <- train2.df$label
y_train.ohe <- to_categorical(y_train)
X_test <- select(test2.df, -label)
y_test <- test2.df$label
y_test.ohe <- to_categorical(test2.df$label)
model2 <- keras_model_sequential() %>%
layer_dense(units = 1, activation="relu", input_shape=c(7)) %>%
layer_dense(units = 4, activation="softmax")
model2
model2 %>% compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = c('accuracy'))
model2 %>% fit(
data.matrix(X_train),
y_train.ohe,
epochs=100,
batch_size=32,
validation_split=0.20
)
mod <- model2 %>% evaluate(as.matrix(X_test), y_test.ohe)
loss <- mod[1]
accuracy2 <- mod[2]
pred.prob <- predict(model2, as.matrix(X_test))
pred.class <- apply(pred.prob, 1, function(x) which.max(x)-1)
confMatrix2 <- confusionMatrix(as.factor(pred.class), as.factor(y_test))
confMatrix2
cat(" For one neuron in hidden layer, loss: ", loss , ", Accuracy: ", accuracy2)
pred.class
model3 <- keras_model_sequential() %>%
layer_dense(units = 12, activation="relu", input_shape=c(7)) %>%
layer_dense(units = 4, activation="softmax")
model3 %>% compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = c('accuracy'))
model3 %>% fit(
data.matrix(X_train),
y_train.ohe,
epochs=100,
batch_size=32,
validation_split=0.20
)
mod2 <- model3 %>% evaluate(as.matrix(X_test), y_test.ohe)
loss2 <- mod2[1]
accuracy3 <- mod2[2]
pred.prob2 <- predict(model3, as.matrix(X_test))
pred.class2 <- apply(pred.prob2, 1, function(x) which.max(x)-1)
confMatrix3 <- confusionMatrix(as.factor(pred.class2), as.factor(y_test))
confMatrix3
cat("Best model has 12 neurons in the hidden layer", "\nIn this model, loss: ", loss2 , ", Accuracy: ", accuracy3)
x2 <- confMatrix3[["byClass"]]
sensitivity2 <- x2[1:4]
specificity2 <- x2[5:8]
ppv2 <- x2[9:12]
Bal_acc2 <- x2[41:44]
accuracy4 <- confMatrix3$overall['Accuracy']
cat("      Best Neural Network Model \n\t Overall accuracy:", accuracy4, "\n\t Sensitivity Class 1:", sensitivity2[1], "Class 2:", sensitivity2[2], "\n\t             Class 3:", sensitivity2[3], "Class 4:", sensitivity2[4], "\n\t Specificity Class 1:", specificity2[1], "Class 2:", specificity2[2], "\n\t\             Class 3:", specificity2[3], "Class 4:", specificity2[4],"\n\t PPV \t     Class 1:", ppv2[1], "Class 2:", ppv2[2], "\n\t             Class3: ", ppv2[3], "Class 4:", ppv2[4], "\n\t Bal. Acc.   Class 1:", Bal_acc2[1], "Class 2:", Bal_acc2[2], "\n\t             Class 3:", Bal_acc2[3], "Class 4:", Bal_acc2[4])
